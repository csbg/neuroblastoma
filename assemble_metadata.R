# Combine metadata generated by extract_seurat_data.R, cell_types.R, and
# make_subclusters.R into a single data frame.
#
# Creates two files:
# * nb_metadata.csv - combined metadata exported via `write_csv()`
# * nb_metadata.rds - combined metadata stored with factor levels

library(tidyverse)



# Functions ---------------------------------------------------------------

#' Load cell type data from SingleR.
#'
#' @param folder Folder containing nb_singler.csv as generated by
#'   cell_types_singler.R
#'
#' @return A dataframe with one row per cell abd 14 columns:
#'   * `first.labels`,
#'     `tuning.scores.first`,
#'     `tuning.scores.second`,
#'     `labels`: reused from the output of `SingleR::SingleR()`
#'   * `median_score`: median of cell type-specific correlation scores
#'   * `diff_next`: difference between the best score and next best score
#'   * `label_score`: score for the assigned label
#'   * `delta_score`: difference between `label_score` and `median_score`
#'   * `median_delta_score`: median of `delta_score` across all cells
#'                           of the assigned type
#'   * `mad_delta_score`: mean absolute deviation
#'   * `z_score`: `delta_score` normalized via median and MAD
load_singler_data <- function(folder) {
  df <- 
    read_csv(str_glue("{folder}/nb_singler.csv")) %>%
    rowwise() %>% 
    mutate(median_score = median(c_across(starts_with("scores.")))) %>% 
    ungroup() %>% 
    mutate(
      diff_next = tuning.scores.first - tuning.scores.second,
      label_name = str_glue("scores.{make.names(labels)}")
    ) %>% 
    pivot_longer(
      starts_with("scores."),
      names_to = "scores",
      values_to = "label_score"
    ) %>% 
    filter(scores == label_name) %>% 
    mutate(delta_score = label_score - median_score) %>% 
    select(!c(pruned.labels, label_name, scores))
  
  left_join(
    df,
    df %>% 
      group_by(labels) %>% 
      summarise(
        median_delta_score = median(delta_score),
        mad_delta_score = mad(delta_score)
      ),
    by = "labels"
  ) %>% 
    mutate(z_score = (delta_score - median_delta_score) / mad_delta_score)
}

#' Load Seurat data from several CSV files.
#' 
#' @param folder Folder containing CSV as generated by extract_seurat_data.R
#'
#' @return A dataframe with one row per cell and columns containing UMAP/tSNE
#'   coordinates, cluster IDs, and patent groups.
load_seurat_data <- function(folder) {
  files <- c(
    "nb_general.csv",
    "nb_clusters_0.2.csv",
    "nb_clusters_0.5.csv",
    "nb_clusters_0.8.csv",
    "nb_tsne.csv",
    "nb_umap.csv",
    "nb_subclusters.csv",
    "nb_gene_signatures.csv"
  )
  
  nb_groups <-
    read_csv(
      "data_raw/metadata/sample_groups.csv",
      col_types = "ccf",
      comment = "#"
    ) %>%
    distinct(sample, group) %>% 
    mutate(group = fct_relevel(group, "I", "II", "III", "IV")) %>%
    arrange(group, sample) %>%
    mutate(sample = as_factor(sample), sample_id = as.integer(sample))
  
  str_glue("{folder}/{files}") %>% 
    map(read_csv) %>% 
    reduce(left_join, by = c("cell", "sample")) %>%
    left_join(nb_groups, by = "sample") %>%
    mutate(
      sample = as_factor(sample) %>% fct_reorder(sample_id),
      across(matches("0\\.\\d"), ~as_factor(.x) %>% fct_inseq())
    ) %>%
    select(!sample_id)
}

#' Combine Seurat and SingleR data.
#'
#' @param df_seurat Dataframe returned by `load_seurat_data()`
#' @param df_singler Dataframe returned by `load_singler_data()` 
#' @param min_z_score Minimum z score, ...
#' @param min_delta_score minimum delta score, ...
#' @param min_diff_next ... and minimum `diff_next` for a cell type label to be
#'   retained. Other labels are set to `NA`. This filtering essentially
#'   reproduces the functionality of `SingleR::pruneScores()`.
#'
#' @return The dataframe provided by `df_seurat`, with two additional columns
#'   `cell_type_fine` and `cell_type_broad`.
add_cell_types <- function(df_seurat,
                           df_singler,
                           min_z_score = -3,
                           min_delta_score = -Inf,
                           min_diff_next = 0) {
  df_singler <- 
    df_singler %>% 
    mutate(
      labels_pruned = case_when(
        z_score >= min_z_score &
          delta_score >= min_delta_score &
          diff_next > min_diff_next
        ~ labels,
        TRUE
        ~ NA_character_
      )
    ) %>% 
    select(cell, sample, cell_type_fine = labels_pruned) %>% 
    extract(
      cell_type_fine,
      into = "cell_type_broad",
      regex = "([^:]*)",
      remove = FALSE
    ) %>%
    mutate(across(starts_with("cell_type"), ~as_factor(.x) %>% fct_infreq()))
  
  left_join(df_seurat, df_singler, by = c("cell", "sample"))
}

add_refined_clusters <- function(df_seurat, folder) {
  refined_cluster_file <- str_glue("{folder}/manual/subcluster_mapping.csv")
  
  df_seurat %>% 
    mutate(
      supercluster = as.character(integrated_snn_res.0.5),
      subcluster = as.character(subcluster_mid_0.2)
    ) %>% 
    left_join(
      read_csv(refined_cluster_file, col_types = "ccc"),
      by = c("supercluster", "subcluster")
    ) %>% 
    select(!c(supercluster, subcluster)) %>% 
    mutate(
      refined_cluster =
        refined_cluster %>% 
        coalesce(integrated_snn_res.0.5) %>% 
        as_factor() %>% 
        fct_relevel(function(l) str_sort(l, numeric = TRUE))
    )
}



# Load data ---------------------------------------------------------------

folder <- "data_generated/all_datasets_current"

singler_data <- load_singler_data(folder)

nb_data <-
  load_seurat_data(folder) %>% 
  add_cell_types(singler_data) %>% 
  mutate(
    cell_type_fine_lumped = fct_lump_n(cell_type_fine, 24),
    cell_type_broad_lumped = fct_lump_prop(cell_type_broad, 0.01)
  ) %>% 
  add_refined_clusters(folder) %>%
  {.}



# Export data -------------------------------------------------------------

nb_data %>% write_csv(str_glue("{folder}/nb_metadata.csv"))
nb_data %>% saveRDS(str_glue("{folder}/nb_metadata.rds"))
